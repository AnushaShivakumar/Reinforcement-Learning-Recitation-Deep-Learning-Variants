{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eeje4O8fviH",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Highway with SB3's DQN\n",
        "* Example code from Highway-env\n",
        "##  Warming up\n",
        "We start with a few useful installs and imports:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzMSuJEOfviP",
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        }
      },
      "source": [
        "# Install environment and agent\n",
        "!pip install highway-env\n",
        "# TODO: we use the bleeding edge version because the current stable version does not support the latest gym>=0.21 versions. Revert back to stable at the next SB3 release.\n",
        "!pip install git+https://github.com/DLR-RM/stable-baselines3\n",
        "\n",
        "# Environment\n",
        "import gymnasium as gym\n",
        "import highway_env\n",
        "\n",
        "# Agent\n",
        "from stable_baselines3 import DQN\n",
        "\n",
        "# Visualization utils\n",
        "%load_ext tensorboard\n",
        "import sys\n",
        "from tqdm.notebook import trange\n",
        "!pip install tensorboardx gym pyvirtualdisplay\n",
        "!apt-get install -y xvfb python3-opengl ffmpeg\n",
        "!git clone https://github.com/eleurent/highway-env.git 2> /dev/null\n",
        "sys.path.insert(0, '/content/highway-env/scripts/')\n",
        "from utils import record_videos, show_videos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "_wACJRDjqP-f"
      },
      "source": [
        "## Training\n",
        "Run tensorboard, cell 7, ***immediately after*** starting\n",
        "cell 8, so there is training output to read\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "%tensorboard --logdir \"highway_dqn\""
      ],
      "metadata": {
        "pycharm": {
          "name": "#%% \n"
        },
        "id": "ZSRTtNNzE5nL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%% \n"
        },
        "id": "Y5TOvonYqP-g"
      },
      "source": [
        "model = DQN('MlpPolicy', 'highway-fast-v0',\n",
        "                policy_kwargs=dict(net_arch=[256, 256]),\n",
        "                learning_rate=5e-4,\n",
        "                buffer_size=15000,\n",
        "                learning_starts=200,\n",
        "                batch_size=32,\n",
        "                gamma=0.8,\n",
        "                train_freq=1,\n",
        "                gradient_steps=1,\n",
        "                target_update_interval=50,\n",
        "                exploration_fraction=0.7,\n",
        "                verbose=1,\n",
        "                tensorboard_log='highway_dqn/')\n",
        "model.learn(int(2e4))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2Bu_Pqop0E7"
      },
      "source": [
        "## Testing\n",
        "\n",
        "Visualize a few episodes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOcOP7Of18T2",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "env = gym.make('highway-fast-v0', render_mode='rgb_array')\n",
        "env = record_videos(env)\n",
        "for episode in trange(3, desc='Test episodes'):\n",
        "    (obs, info), done = env.reset(), False\n",
        "    while not done:\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        obs, reward, done, truncated, info = env.step(int(action))\n",
        "env.close()\n",
        "show_videos()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment**\n",
        "* Train a DQN agent to survive at least 20 seconds in the highway-fast-v0 env\n",
        "  * Document your training process\n",
        "* Evaluate the effects of a low and a high hyperparameter value for learning rate, batch_size and target_update_interval\n",
        "  * Report and explain results\n",
        "* Choose another RL algorithm (PPO, A2C, DDPG,...) available in stable-baselines3 and use it to train an agent in the highway-fast-v0 env\n",
        "  * Report, explain and contrast your results with those of your original DQN agent\n",
        "* Documentation should include plots from tensor board, videos, etc. Make sure to revise the log directory (i.e. *tensorboard_log*) every time you run experiments with different settings so the results will be stored separately. Use tensorboard to visualize the training results and compare model performance.  Project report should provide rationales for choices and experiments and explanations for results, particularly those that were unexpected.\n",
        "* For extra credit you may try additional learning algorithms or experiment with improving agent performance in other ways (e,g, novel model structure, observation space, self-attention, LSTM)"
      ],
      "metadata": {
        "id": "VAFoWniF7vbU"
      }
    }
  ]
}